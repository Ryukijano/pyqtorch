{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to pyqtorch","text":"<p>pyqtorch is a state vector simulator designed for quantum machine learning written in PyTorch. It allows for building fully differentiable quantum circuits comprised of both digital and analog operations using a intuitive torch.nn.Module-based API. It can be used standalone as shown in these docs, or through our framework for quantum programming: Qadence.</p>"},{"location":"#setup","title":"Setup","text":"<p>To install <code>pyqtorch</code> , you can go into any virtual environment of your choice and install it normally with <code>pip</code>:</p> <pre><code>pip install pyqtorch\n</code></pre>"},{"location":"#digital-operations","title":"Digital Operations","text":"<p><code>pyqtorch</code> implements a large selection of both primitive and parametric single to n-qubit, digital quantum gates.</p> <p>Let's have a look at primitive gates first.</p> <pre><code>import torch\nfrom pyqtorch import X, CNOT, random_state\n\nx = X(0)\nstate = random_state(n_qubits=2)\n\nnew_state = x(state)\n\ncnot = CNOT(0,1)\nnew_state= cnot(state)\n</code></pre> <p>Parametric gates can be initialized with or without a <code>param_name</code>. In the former case, a dictionary containing the <code>param_name</code> and a <code>torch.Tensor</code> for the parameter is expected when calling the forward method of the gate.</p> <pre><code>import torch\nfrom pyqtorch import X, RX, CNOT, CRX, random_state\n\nstate = random_state(n_qubits=2)\n\nrx_with_param = RX(0, 'theta')\n\ntheta = torch.rand(1)\nvalues = {'theta': theta}\nnew_state = rx_with_param(state, values)\n\ncrx = CRX(0, 1, 'theta')\nnew_state = crx(state, values)\n</code></pre> <p>However, if you want to run a quick state vector simulation, you can initialize parametric gates without passing a <code>param_name</code>, in which case the forward method of the gate will simply expect a <code>torch.Tensor</code>.</p> <pre><code>import torch\nfrom pyqtorch import RX, random_state\n\nstate = random_state(n_qubits=2)\nrx = RX(0)\nnew_state = rx(state, torch.rand(1))\n</code></pre>"},{"location":"#analog-operations","title":"Analog Operations","text":"<p>An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), the evolution operator is \\(\\exp(-i\\mathcal{H}t)\\).</p> <p><code>pyqtorch</code> also contains a <code>analog</code> module which allows for global state evolution through the <code>HamiltonianEvolution</code> class. There exists several ways to pass a generator, and we present them in Analog Operations. Below, we show an example where the generator \\(\\mathcal{H}\\) is an arbitrary tensor. To build arbitrary Pauli hamiltonians, we recommend using Qadence.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution, is_normalized\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 4\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\n# To be evolved for a batch of times\nt_list = torch.tensor([0.0, 0.5, 1.0, 2.0])\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, t_list, [i for i in range(n_qubits)])\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns an evolved state at each time value\npsi_end = hamiltonian_evolution(\n    state = psi_start)\n\nassert is_normalized(psi_end, atol=1e-05)\n</code></pre>"},{"location":"#circuits","title":"Circuits","text":"<p>Using digital and analog operations, you can can build fully differentiable quantum circuits using the <code>QuantumCircuit</code> class; note that the default differentiation mode in pyqtorch is using torch.autograd.</p> <pre><code>import torch\nimport pyqtorch as pyq\n\nrx = pyq.RX(0, param_name=\"theta\")\ny = pyq.Y(0)\ncnot = pyq.CNOT(0, 1)\nops = [rx, y, cnot]\nn_qubits = 2\ncirc = pyq.QuantumCircuit(n_qubits, ops)\nstate = pyq.random_state(n_qubits)\ntheta = torch.rand(1, requires_grad=True)\nobs = pyq.QuantumCircuit(n_qubits, [pyq.Z(0)])\nexpval = pyq.expectation(circ, state, {\"theta\": theta}, obs)\ndfdtheta = torch.autograd.grad(expval, theta, torch.ones_like(expval))\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to Contribute","text":"<p>We're grateful for your interest in participating in pyqtorch! Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an Issue or Proposing a Feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to PyQ, feel free to create an issue on pyqtorch's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>We're excited that you're eager to contribute to pyqtorch! To contribute, fork the <code>main</code> branch of pyqtorch repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/pyqtorch</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/pyqtorch.git\n</code></pre> <p>Next, navigate to your new pyqtorch fork directory and mark the main pyqtorch repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/pyqtorch.git\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within pyqtorch, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run pyqtorch tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\n\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful Things for your workflow: Linting and Testing","text":"<p>Use <code>pre-commit</code> hooks to make sure that the code is properly linted before pushing a new commit. Make sure that the unit tests and type checks are passing since the merge request will not be accepted if the automatic CI/CD pipeline do not pass.</p> <p>Without <code>hatch</code>:</p> <pre><code>pip install pytest\n\npip install -e .\npip install pre-commit\npre-commit install\npre-commit run --all-files\npytest\n</code></pre> <p>And with <code>hatch</code>:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Make sure your docs build too!</p> <p>With <code>hatch</code>:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"analog/","title":"Analog Operations","text":""},{"location":"analog/#analog-operations","title":"Analog Operations","text":"<p>An analog operation is one whose unitary is best described by the evolution of some hermitian generator, or Hamiltonian, acting on an arbitrary number of qubits. For a time-independent generator \\(\\mathcal{H}\\) and some time variable \\(t\\), the evolution operator is \\(\\exp(-i\\mathcal{H}t)\\). <code>pyqtorch</code> provides the HamiltonianEvolution class to initialize analog operations. There exists several ways to pass a generator, and we present them next.</p>"},{"location":"analog/#tensor-generator","title":"Tensor generator","text":"<p>The first case of generator we can provide is simply an arbitrary hermitian tensor. Note we can use a string for defining the time evolution as a parameter, instead of directly passing a tensor.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\ntime = torch.tensor([1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: time})\n\nprint(psi_end)\n</code></pre>   tensor([[[-0.3265+0.1856j],          [-0.4837+0.5839j]],          [[-0.3415+0.2041j],          [-0.2817+0.2154j]]], dtype=torch.complex128)"},{"location":"analog/#symbol-generator","title":"Symbol generator","text":"<p>We can also have a symbol generator to be replaced later by any hermitian matrix. and in this case we use a string symbol to instantiate <code>HamiltonianEvolution</code>.</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Symbol hamiltonian\nhermitian_symbol = \"h\"\n\ntime = torch.tensor([1.0])\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_symbol, time, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Set the value for h\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nH = matrix + matrix.T.conj()\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={hermitian_symbol: H})\n\nprint(psi_end)\n</code></pre>   tensor([[[-0.2473+0.5048j],          [-0.0868+0.4920j]],          [[ 0.3963+0.2555j],          [-0.0918+0.4514j]]], dtype=torch.complex128)"},{"location":"analog/#sequence-generator","title":"Sequence generator","text":"<p>The generator can be also a sequence of operators such as a quantum circuit:</p> <pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution, X, Y\nfrom pyqtorch import Add, QuantumCircuit\n\nn_qubits = 2\n\nops = [X, Y] * 2\nqubit_targets = list(range(n_qubits))\ngenerator = QuantumCircuit(\n    n_qubits,\n    [\n        Add([op(q) for op, q in zip(ops, qubit_targets)]),\n        *[op(q) for op, q in zip(ops, qubit_targets)],\n    ],\n)\n\ntime = torch.tensor([1.0])\n\nhamiltonian_evolution = HamiltonianEvolution(generator, time, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start)\n\nprint(psi_end)\n</code></pre>   tensor([[[-0.0814+0.1267j],          [ 0.3733-0.5814j]],          [[-0.0814+0.1267j],          [ 0.3733-0.5814j]]], dtype=torch.complex128)"},{"location":"analog/#batched-execution","title":"Batched execution","text":"<p>We also allow for different ways to run analog operations on batched inputs. We can have batched evolution times, or batched generators. Below we show a few examples.</p>"},{"location":"analog/#batched-evolution-times","title":"Batched evolution times","text":"<pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nhermitian_matrix = matrix + matrix.T.conj()\n\ntimes = torch.tensor([0.25, 0.5, 0.75, 1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_matrix, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: times})\n\nprint(psi_end.size())\n</code></pre>   torch.Size([2, 2, 4])"},{"location":"analog/#batched-generators","title":"Batched generators","text":"<pre><code>import torch\nfrom pyqtorch import uniform_state, HamiltonianEvolution\nfrom pyqtorch.matrices import DEFAULT_MATRIX_DTYPE\n\nn_qubits = 2\nqubit_targets = list(range(n_qubits))\n\n# Random hermitian hamiltonian\nmatrix = torch.rand(2**n_qubits, 2**n_qubits, dtype=DEFAULT_MATRIX_DTYPE)\nH = matrix + matrix.T.conj()\nhermitian_batch = torch.stack((H, H.conj()), dim=2)\n\ntime = torch.tensor([1.0])\ntime_symbol = \"t\"\n\nhamiltonian_evolution = HamiltonianEvolution(hermitian_batch, time_symbol, qubit_targets)\n\n# Starting from a uniform state\npsi_start = uniform_state(n_qubits)\n\n# Returns the evolved state\npsi_end = hamiltonian_evolution(state = psi_start, values={time_symbol: time})\n\nprint(psi_end.size())\n</code></pre>   torch.Size([2, 2, 2])"},{"location":"api/","title":"API","text":"<p><code>pyqtorch</code> exposes <code>run</code>, <code>sample</code> and <code>expectation</code> routines with the following interface:</p>"},{"location":"api/#run","title":"run","text":"<pre><code>def run(\n    circuit: QuantumCircuit,\n    state: Tensor = None,\n    values: dict[str, Tensor] = dict(),\n    embedding: Embedding | None = None,\n) -&gt; Tensor:\n    \"\"\"Sequentially apply each operation in `circuit.operations` to an input state `state`\n    given current parameter values `values`, perform an optional `embedding` on `values`\n    and return an output state.\n\n    Arguments:\n    circuit: A pyqtorch.QuantumCircuit instance.\n    state: A torch.Tensor of shape [2, 2, ..., batch_size].\n    values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs denoting\n            the current parameter values for each parameter in `circuit`.\n    embedding: An optional instance of `Embedding`.\n    Returns:\n         A torch.Tensor of shape [2, 2, ..., batch_size]\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/#sample","title":"sample","text":"<pre><code>def sample(\n    circuit: QuantumCircuit,\n    state: Tensor = None,\n    values: dict[str, Tensor] = dict(),\n    n_shots: int = 1000,\n    embedding: Embedding | None = None,\n) -&gt; list[Counter]:\n    \"\"\"Sample from `circuit` given an input state `state` given current parameter values `values`,\n       perform an optional `embedding` on `values` and return a list Counter objects mapping from\n       bitstring: num_samples.\n\n    Arguments:\n    circuit: A pyqtorch.QuantumCircuit instance.\n    state: A torch.Tensor of shape [2, 2, ..., batch_size].\n    values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs\n            denoting the current parameter values for each parameter in `circuit`.\n    n_shots: A positive int denoting the number of requested samples.\n    embedding: An optional instance of `Embedding`.\n    Returns:\n         A list of Counter objects containing bitstring:num_samples pairs.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/#expectation","title":"expectation","text":"<pre><code>def expectation(\n    circuit: QuantumCircuit,\n    state: Tensor,\n    values: dict[str, Tensor],\n    observable: Observable,\n    diff_mode: DiffMode = DiffMode.AD,\n    embedding: Embedding | None = None,\n) -&gt; Tensor:\n    \"\"\"Compute the expectation value of `circuit` given a `state`, parameter values `values`\n        given an `observable` and optionally compute gradients using diff_mode.\n    Arguments:\n        circuit: A pyqtorch.QuantumCircuit instance.\n        state: A torch.Tensor of shape [2, 2, ..., batch_size].\n        values: A dictionary containing &lt;'parameter_name': torch.Tensor&gt; pairs\n                denoting the current parameter values for each parameter in `circuit`.\n        observable: A pyq.Observable instance.\n        diff_mode: The differentiation mode.\n        embedding: An optional instance of `Embedding`.\n    Returns:\n        An expectation value.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"cuda_debugging/","title":"CUDA Profiling and debugging","text":"<p>To debug your quantum programs on <code>CUDA</code> devices, <code>pyqtorch</code> offers a <code>DEBUG</code> mode, which can be activated via setting the <code>PYQ_LOG_LEVEL</code> environment variable.</p> <pre><code>export PYQ_LOG_LEVEL=DEBUG\n</code></pre> <p>Before running your script, make sure to install the following packages:</p> <p><pre><code>pip install nvidia-pyindex\npip install nvidia-dlprof[pytorch]\n</code></pre> For more information, check the dlprof docs.</p>"},{"location":"differentiation/","title":"Differentiation","text":"<p><code>pyqtorch</code> also offers several differentiation modes to compute gradients which can be accessed through the <code>expectation</code> API. Simply pass one of three <code>DiffMode</code> options to the <code>diff_mode</code> argument. The default is <code>ad</code>.</p>"},{"location":"differentiation/#automatic-differentiation-diffmodead","title":"Automatic Differentiation (DiffMode.AD)","text":"<p>The default differentation mode of <code>pyqtorch</code>, torch.autograd. It uses the <code>torch</code> native automatic differentiation engine which tracks operations on <code>torch.Tensor</code> objects by constructing a computational graph to perform chain rules for derivatives calculations.</p>"},{"location":"differentiation/#adjoint-differentiation-diffmodeadjoint","title":"Adjoint Differentiation (DiffMode.ADJOINT)","text":"<p>The adjoint differentiation mode computes first-order gradients by only requiring at most three states in memory in <code>O(P)</code> time where <code>P</code> is the number of parameters in a circuit.</p>"},{"location":"differentiation/#generalized-parameter-shift-rules-diffmodegpsr","title":"Generalized Parameter-Shift rules (DiffMode.GPSR)","text":"<p>The Generalized parameter shift rule (GPSR mode) is an extension of the well known parameter shift rule (PSR) algorithm to arbitrary quantum operations. Indeed, PSR only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, GPSR extending to multi-gap.</p> <p>Usage restrictions</p> <p>At the moment, only operations with two distinct eigenvalues from their generator (single gap shift rule) are supported. The multi gap case will be supported in a later release. Circuits with one or more Scale or HamiltonianEvolution operations are not supported. Finally, circuits with operations sharing a same parameter name are also not supported.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"differentiation/#example","title":"Example","text":"<pre><code>import pyqtorch as pyq\nimport torch\nfrom pyqtorch.utils import DiffMode\n\nn_qubits = 3\nbatch_size = 1\n\nry = pyq.RY(0, param_name=\"x\")\ncnot = pyq.CNOT(1, 2)\nops = [ry]\nn_qubits = 3\ncirc = pyq.QuantumCircuit(n_qubits, ops)\n\nobs = pyq.QuantumCircuit(n_qubits, [pyq.Z(0)])\nstate = pyq.zero_state(n_qubits)\n\nvalues_ad = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\nvalues_adjoint = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\nvalues_gpsr = {\"x\": torch.tensor([torch.pi / 2], requires_grad=True)}\n\nexp_ad = pyq.expectation(circ, state, values_ad, obs, DiffMode.AD)\nexp_adjoint = pyq.expectation(circ, state, values_adjoint, obs, DiffMode.ADJOINT)\nexp_gpsr = pyq.expectation(circ, state, values_gpsr, obs, DiffMode.GPSR)\n\ndfdx_ad = torch.autograd.grad(exp_ad, tuple(values_ad.values()), torch.ones_like(exp_ad))\n\ndfdx_adjoint = torch.autograd.grad(\n    exp_adjoint, tuple(values_adjoint.values()), torch.ones_like(exp_adjoint)\n)\n\ndfdx_gpsr = torch.autograd.grad(\n    exp_gpsr, tuple(values_gpsr.values()), torch.ones_like(exp_gpsr)\n)\n\nassert len(dfdx_ad) == len(dfdx_adjoint) == len(dfdx_gpsr)\nfor i in range(len(dfdx_ad)):\n    assert torch.allclose(dfdx_ad[i], dfdx_adjoint[i])\n    assert torch.allclose(dfdx_ad[i], dfdx_gpsr[i])\n</code></pre>"},{"location":"dropout/","title":"Quantum Dropout","text":"<p>Coming soon.</p>"},{"location":"embed/","title":"Use Arbitrary Expressions as Gate Parameters via Embedding","text":"<p>By default, a <code>Parametric</code> operation expects a <code>values</code> dict with a value for its parameter in the forward-pass when initialized using a <code>str</code> parameter.</p>"},{"location":"embed/#using-arbitrary-expressions-as-parameters","title":"Using arbitrary expressions as parameters","text":"<p><code>pyqtorch</code> allows for using arbitary expressions as parameters, for instance <code>sin(x)</code> where <code>x</code> can be a FeatureParameter. To do so, a name has to be assigned to the outcome of the evaluation of <code>sin(x)</code> and supplied to the <code>pyq.QuantumCircuit</code> within an instance of <code>Embedding</code>.</p>"},{"location":"embed/#creating-parameter-expressions-using-concretizedcallable","title":"Creating parameter expressions using <code>ConcretizedCallable</code>","text":"<p><code>pyq.ConcretizedCallable</code> expects a name for a function and a list of arguments <pre><code>import torch\nimport pyqtorch as pyq\nsin_x, sin_x_fn = 'sin_x', pyq.ConcretizedCallable(call_name = 'sin', abstract_args=['x'])\n# We can now evaluate sin_x_fn using a values dict\nx = torch.rand(1, requires_grad=True)\nvalues = {'x': x}\nresult = sin_x_fn(values)\nprint(torch.autograd.grad(result, x, torch.ones_like(result))[0])\n</code></pre>   tensor([0.7352])   </p>"},{"location":"embed/#interfacing-concretizedcallable-with-quantumcircuit-parameters-via-the-embedding-class","title":"Interfacing <code>ConcretizedCallable</code> with QuantumCircuit parameters via the <code>Embedding</code> class","text":"<p>Lets use <code>sin_x</code> in another callable, so our gate will be parametrized by the result of the expression <code>y * sin(x)</code> where <code>y</code> is trainable and <code>x</code> is a feature parameter. We can tell <code>pyq</code> how to associate each callable with its underlying parameters via the <code>Embedding</code> class which expects arguments regarding what are trainable and non-trainable symbols.</p> <pre><code>mul_sinx_y, mul_sinx_y_fn = 'mul_sinx_y', pyq.ConcretizedCallable(call_name = 'mul', abstract_args=['sin_x', 'y'])\nembedding = pyq.Embedding(vparam_names=['y'], fparam_names=['x'], var_to_call={sin_x: sin_x_fn, mul_sinx_y: mul_sinx_y_fn})\ncirc = pyq.QuantumCircuit(1, [pyq.RX(0, mul_sinx_y)])\nstate= pyq.zero_state(1)\ny = torch.rand(1, requires_grad=True)\nvalues = {'x': x, 'y': y}\nexpval = pyq.expectation(circuit=circ, state=state, values=values, observable= pyq.Observable(1, [pyq.Z(0)]),diff_mode=pyq.DiffMode.AD,embedding=embedding)\nprint(torch.autograd.grad(expval, (x, y), torch.ones_like(expval)))\n</code></pre>   (tensor([-0.3090]), tensor([-0.3528]))"},{"location":"embed/#tracking-and-reembedding-a-tracked-parameter","title":"Tracking and Reembedding a tracked parameter","text":"<p>For specific usecases, a <code>tparam</code> argument can be passed to the <code>Embedding</code> which tells the class to track the computations depending on it which enables for their efficient recomputation given different values for <code>tparam</code>.</p> <pre><code>v_params = [\"theta\"]\nf_params = [\"x\"]\ntparam = \"t\"\nleaf0, native_call0 = \"%0\", pyq.ConcretizedCallable(\n    \"mul\", [\"x\", \"theta\"], {}\n)\nleaf1, native_call1 = \"%1\", pyq.ConcretizedCallable(\n    \"mul\", [\"t\", \"%0\"], {}\n)\n\nleaf2, native_call2 = \"%2\", pyq.ConcretizedCallable(\"sin\", [\"%1\"], {})\nembedding = pyq.Embedding(\n    v_params,\n    f_params,\n    var_to_call={leaf0: native_call0, leaf1: native_call1, leaf2: native_call2},\n    tparam_name=tparam,\n)\ninputs = {\n    \"x\": torch.rand(1),\n    \"theta\": torch.rand(1),\n    tparam: torch.rand(1),\n}\nall_params = embedding.embed_all(inputs)\nprint(f'{leaf2} value before reembedding: {all_params[leaf2]}')\nnew_tparam_val = torch.rand(1)\nreembedded_params = embedding.reembed_tparam(all_params, new_tparam_val)\nprint(f'{leaf2} value after reembedding: {reembedded_params[leaf2]}')\n</code></pre>   %2 value before reembedding: tensor([0.1358]) %2 value after reembedding: tensor([0.0134])"},{"location":"embed/#see-the-docstrings-for-more-details-and-examples","title":"See the docstrings for more details and examples:","text":""},{"location":"embed/#concretizedcallable","title":"ConcretizedCallable","text":"<p>Transform an abstract function name and arguments into     a callable in a linear algebra engine which can be evaluated     using user input. Arguments:     call_name: The name of the function.     abstract_args: A list of arguments to the function,                    can be numeric types for constants or strings for parameters     instruction_mapping: A dict containing user-passed mappings from a function name                         to its implementation.     engine_name: The name of the framework to use.     device: Which device to use.</p> <p>Example: <pre><code>import torch\n\nfrom pyqtorch.embed import ConcretizedCallable\n\n\nIn [11]: call = ConcretizedCallable('sin', ['x'], engine_name='numpy')\nIn [12]: call({'x': 0.5})\nOut[12]: 0.479425538604203\n\nIn [13]: call = ConcretizedCallable('sin', ['x'], engine_name='torch')\nIn [14]: call({'x': torch.rand(1)})\nOut[14]: tensor([0.5531])\n\nIn [15]: call = ConcretizedCallable('sin', ['x'], engine_name='jax')\nIn [16]: call({'x': 0.5})\nOut[16]: Array(0.47942555, dtype=float32, weak_type=True)\n</code></pre></p> Source code in <code>pyqtorch/embed.py</code> <pre><code>class ConcretizedCallable:\n    \"\"\"Transform an abstract function name and arguments into\n        a callable in a linear algebra engine which can be evaluated\n        using user input.\n    Arguments:\n        call_name: The name of the function.\n        abstract_args: A list of arguments to the function,\n                       can be numeric types for constants or strings for parameters\n        instruction_mapping: A dict containing user-passed mappings from a function name\n                            to its implementation.\n        engine_name: The name of the framework to use.\n        device: Which device to use.\n\n    Example:\n    ```\n    import torch\n\n    from pyqtorch.embed import ConcretizedCallable\n\n\n    In [11]: call = ConcretizedCallable('sin', ['x'], engine_name='numpy')\n    In [12]: call({'x': 0.5})\n    Out[12]: 0.479425538604203\n\n    In [13]: call = ConcretizedCallable('sin', ['x'], engine_name='torch')\n    In [14]: call({'x': torch.rand(1)})\n    Out[14]: tensor([0.5531])\n\n    In [15]: call = ConcretizedCallable('sin', ['x'], engine_name='jax')\n    In [16]: call({'x': 0.5})\n    Out[16]: Array(0.47942555, dtype=float32, weak_type=True)\n    ```\n\n\n\n    \"\"\"\n\n    def __init__(\n        self,\n        call_name: str,\n        abstract_args: list[str | float | int],\n        instruction_mapping: dict[str, Tuple[str, str]] = dict(),\n        engine_name: str = \"torch\",\n        device: str = \"cpu\",\n        dtype: Any = None,\n    ) -&gt; None:\n        instruction_mapping = {\n            **instruction_mapping,\n            **DEFAULT_INSTRUCTION_MAPPING[engine_name],\n        }\n        self.call_name = call_name\n        self.abstract_args = abstract_args\n        self.engine_name = engine_name\n        self._device = device\n        self._dtype = dtype\n        self.engine_call = None\n        engine = None\n        try:\n            engine_name, fn_name = ARRAYLIKE_FN_MAP[engine_name]\n            engine = import_module(engine_name)\n            self.arraylike_fn = getattr(engine, fn_name)\n        except (ModuleNotFoundError, ImportError) as e:\n            logger.error(f\"Unable to import {engine_name} due to {e}.\")\n\n        try:\n            self.engine_call = getattr(engine, call_name, None)\n            if self.engine_call is None:\n                mod, fn = instruction_mapping[call_name]\n                self.engine_call = getattr(import_module(mod), fn)\n        except (ImportError, KeyError) as e:\n            logger.error(\n                f\"Requested function {call_name} can not be imported from {engine_name} and is\"\n                + f\" not in instruction_mapping {instruction_mapping} due to {e}.\"\n            )\n\n    def evaluate(self, inputs: dict[str, ArrayLike] = dict()) -&gt; ArrayLike:\n        arraylike_args = []\n        for symbol_or_numeric in self.abstract_args:\n            if isinstance(symbol_or_numeric, (float, int)):\n                arraylike_args.append(\n                    self.arraylike_fn(symbol_or_numeric, device=self.device)\n                )\n            elif isinstance(symbol_or_numeric, str):\n                arraylike_args.append(inputs[symbol_or_numeric])\n        return self.engine_call(*arraylike_args)  # type: ignore[misc]\n\n    def __call__(self, inputs: dict[str, ArrayLike] = dict()) -&gt; ArrayLike:\n        return self.evaluate(inputs)\n\n    @property\n    def device(self) -&gt; str:\n        return self._device\n\n    @property\n    def dtype(self) -&gt; Any:\n        return self._dtype\n\n    def to(self, *args: Any, **kwargs: Any) -&gt; ConcretizedCallable:\n        self._device = kwargs.get(\"device\", None)\n        self._dtype = kwargs.get(\"dtype\", None)\n        return self\n</code></pre>"},{"location":"embed/#embedding","title":"Embedding","text":"<p>A class relating variational and feature parameters used in ConcretizedCallable instances to parameter names used in gates.</p> <p>Parameters:</p> Name Type Description Default <code>vparam_names</code> <code>list[str]</code> <p>A list of variational parameters.</p> <code>[]</code> <code>fparam_names</code> <code>list[str]</code> <p>A list of feature parameters.</p> <code>[]</code> <code>var_to_call</code> <code>dict[str, ConcretizedCallable]</code> <p>A dict mapping from &lt;<code>parameter_name</code>: ConcretizedCallable&gt; pairs,.</p> <code>dict()</code> <code>tparam_name</code> <code>Optional[str]</code> <p>Optional name for a time parameter.</p> <code>None</code> <code>engine_name</code> <code>str</code> <p>The name of the linear algebra engine.</p> <code>'torch'</code> <code>device</code> <code>str</code> <p>The device to use</p> <code>'cpu'</code> <p>Example: <pre><code>from __future__ import annotations\n\nimport numpy as np\nimport pytest\nimport torch\nimport torch.autograd.gradcheck\n\nimport pyqtorch as pyq\nfrom pyqtorch.embed import ConcretizedCallable, Embedding\nname0, fn0 = \"fn0\", ConcretizedCallable(\"sin\", [\"x\"])\nname1, fn1 = \"fn1\", ConcretizedCallable(\"mul\", [\"fn0\", \"y\"])\nname2, fn2 = \"fn2\", ConcretizedCallable(\"mul\", [\"fn1\", 2.0])\nname3, fn3 = \"fn3\", ConcretizedCallable(\"log\", [\"fn2\"])\nembedding = pyq.Embedding(\n    vparam_names=[\"x\"],\n    fparam_names=[\"y\"],\n    var_to_call={name0: fn0, name1: fn1, name2: fn2, name3: fn3},\n)\nrx = pyq.RX(0, param_name=name0)\ncry = pyq.CRY(0, 1, param_name=name1)\nphase = pyq.PHASE(1, param_name=name2)\nry = pyq.RY(1, param_name=name3)\ncnot = pyq.CNOT(1, 2)\nops = [rx, cry, phase, ry, cnot]\nn_qubits = 3\ncirc = pyq.QuantumCircuit(n_qubits, ops)\nobs = pyq.Observable(n_qubits, [pyq.Z(0)])\n\nstate = pyq.zero_state(n_qubits)\n\nx = torch.rand(1, requires_grad=True)\ny = torch.rand(1, requires_grad=True)\n\nvalues_ad = {\"x\": x, \"y\": y}\nembedded_params = embedding(values_ad)\nwf = pyq.run(circ, state, embedded_params, embedding)\n</code></pre></p> Source code in <code>pyqtorch/embed.py</code> <pre><code>class Embedding:\n    \"\"\"A class relating variational and feature parameters used in ConcretizedCallable instances to\n    parameter names used in gates.\n\n    Arguments:\n        vparam_names: A list of variational parameters.\n        fparam_names: A list of feature parameters.\n        var_to_call: A dict mapping from &lt;`parameter_name`: ConcretizedCallable&gt; pairs,.\n        tparam_name: Optional name for a time parameter.\n        engine_name: The name of the linear algebra engine.\n        device: The device to use\n\n    Example:\n    ```\n    from __future__ import annotations\n\n    import numpy as np\n    import pytest\n    import torch\n    import torch.autograd.gradcheck\n\n    import pyqtorch as pyq\n    from pyqtorch.embed import ConcretizedCallable, Embedding\n    name0, fn0 = \"fn0\", ConcretizedCallable(\"sin\", [\"x\"])\n    name1, fn1 = \"fn1\", ConcretizedCallable(\"mul\", [\"fn0\", \"y\"])\n    name2, fn2 = \"fn2\", ConcretizedCallable(\"mul\", [\"fn1\", 2.0])\n    name3, fn3 = \"fn3\", ConcretizedCallable(\"log\", [\"fn2\"])\n    embedding = pyq.Embedding(\n        vparam_names=[\"x\"],\n        fparam_names=[\"y\"],\n        var_to_call={name0: fn0, name1: fn1, name2: fn2, name3: fn3},\n    )\n    rx = pyq.RX(0, param_name=name0)\n    cry = pyq.CRY(0, 1, param_name=name1)\n    phase = pyq.PHASE(1, param_name=name2)\n    ry = pyq.RY(1, param_name=name3)\n    cnot = pyq.CNOT(1, 2)\n    ops = [rx, cry, phase, ry, cnot]\n    n_qubits = 3\n    circ = pyq.QuantumCircuit(n_qubits, ops)\n    obs = pyq.Observable(n_qubits, [pyq.Z(0)])\n\n    state = pyq.zero_state(n_qubits)\n\n    x = torch.rand(1, requires_grad=True)\n    y = torch.rand(1, requires_grad=True)\n\n    values_ad = {\"x\": x, \"y\": y}\n    embedded_params = embedding(values_ad)\n    wf = pyq.run(circ, state, embedded_params, embedding)\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        vparam_names: list[str] = [],\n        fparam_names: list[str] = [],\n        var_to_call: dict[str, ConcretizedCallable] = dict(),\n        tparam_name: Optional[str] = None,\n        engine_name: str = \"torch\",\n        device: str = \"cpu\",\n    ) -&gt; None:\n\n        self.vparams = {\n            vp: init_param(engine_name, trainable=True, device=device)\n            for vp in vparam_names\n        }\n        self.fparam_names: list[str] = fparam_names\n        self.tparam_name = tparam_name\n        self.var_to_call: dict[str, ConcretizedCallable] = var_to_call\n        self._dtype: DTypeLike = None\n        self.tracked_vars: list[str] = []\n        self._device = device\n        self._tracked_vars_identified = False\n        self.engine_name = engine_name\n\n    @property\n    def root_param_names(self) -&gt; list[str]:\n        return list(self.vparams.keys()) + self.fparam_names\n\n    def embed_all(\n        self,\n        inputs: dict[str, ArrayLike] = dict(),\n    ) -&gt; dict[str, ArrayLike]:\n        \"\"\"The standard embedding of all intermediate and leaf parameters.\n        Include the root_params, i.e., the vparams and fparams original values\n        to be reused in computations.\n        \"\"\"\n        for intermediate_or_leaf_var, engine_callable in self.var_to_call.items():\n            # We mutate the original inputs dict and include intermediates and leaves.\n            if not self._tracked_vars_identified:\n                # we do this only on the first embedding call\n                if self.tparam_name and any(\n                    [\n                        p in [self.tparam_name] + self.tracked_vars\n                        for p in engine_callable.abstract_args\n                    ]  # we check if any parameter in the callables args is time\n                    # or depends on an intermediate variable which itself depends on time\n                ):\n                    self.tracked_vars.append(intermediate_or_leaf_var)\n                    # we remember which parameters depend on time\n            inputs[intermediate_or_leaf_var] = engine_callable(inputs)\n        self._tracked_vars_identified = True\n        return inputs\n\n    def reembed_tparam(\n        self,\n        embedded_params: dict[str, ArrayLike],\n        tparam_value: ArrayLike,\n    ) -&gt; dict[str, ArrayLike]:\n        \"\"\"Receive already embedded params containing intermediate and leaf parameters\n        and recalculate the those which are dependent on `tparam_name` using the new value\n        `tparam_value`.\n        \"\"\"\n        if self.tparam_name is None:\n            raise ValueError(\n                \"`reembed_param` requires a `tparam_name` to be passed\\\n                              when initializing the `Embedding` class\"\n            )\n        embedded_params[self.tparam_name] = tparam_value\n        for time_dependent_param in self.tracked_vars:\n            embedded_params[time_dependent_param] = self.var_to_call[\n                time_dependent_param\n            ](embedded_params)\n        return embedded_params\n\n    def __call__(self, inputs: dict[str, ArrayLike] = dict()) -&gt; dict[str, ArrayLike]:\n        \"\"\"Functional version of legacy embedding: Return a new dictionary\\\n        with all embedded parameters.\"\"\"\n        return self.embed_all(inputs)\n\n    @property\n    def dtype(self) -&gt; DTypeLike:\n        return self._dtype\n\n    @property\n    def device(self) -&gt; str:\n        return self._device\n\n    def to(self, *args: Any, **kwargs: Any) -&gt; Embedding:\n        if self.engine_name == \"torch\":\n            # we only support this for torch for now\n            self.vparams = {p: t.to(*args, **kwargs) for p, t in self.vparams.items()}\n            self.var_to_call = {\n                p: call.to(*args, **kwargs) for p, call in self.var_to_call.items()\n            }\n            # Dtype and device have to be passes as kwargs\n            self._dtype = kwargs.get(\"dtype\", self._dtype)\n            self._device = kwargs.get(\"device\", self._device)\n        return self\n</code></pre>"},{"location":"embed/#pyqtorch.embed.Embedding.__call__","title":"<code>__call__(inputs=dict())</code>","text":"<p>Functional version of legacy embedding: Return a new dictionary        with all embedded parameters.</p> Source code in <code>pyqtorch/embed.py</code> <pre><code>def __call__(self, inputs: dict[str, ArrayLike] = dict()) -&gt; dict[str, ArrayLike]:\n    \"\"\"Functional version of legacy embedding: Return a new dictionary\\\n    with all embedded parameters.\"\"\"\n    return self.embed_all(inputs)\n</code></pre>"},{"location":"embed/#pyqtorch.embed.Embedding.embed_all","title":"<code>embed_all(inputs=dict())</code>","text":"<p>The standard embedding of all intermediate and leaf parameters. Include the root_params, i.e., the vparams and fparams original values to be reused in computations.</p> Source code in <code>pyqtorch/embed.py</code> <pre><code>def embed_all(\n    self,\n    inputs: dict[str, ArrayLike] = dict(),\n) -&gt; dict[str, ArrayLike]:\n    \"\"\"The standard embedding of all intermediate and leaf parameters.\n    Include the root_params, i.e., the vparams and fparams original values\n    to be reused in computations.\n    \"\"\"\n    for intermediate_or_leaf_var, engine_callable in self.var_to_call.items():\n        # We mutate the original inputs dict and include intermediates and leaves.\n        if not self._tracked_vars_identified:\n            # we do this only on the first embedding call\n            if self.tparam_name and any(\n                [\n                    p in [self.tparam_name] + self.tracked_vars\n                    for p in engine_callable.abstract_args\n                ]  # we check if any parameter in the callables args is time\n                # or depends on an intermediate variable which itself depends on time\n            ):\n                self.tracked_vars.append(intermediate_or_leaf_var)\n                # we remember which parameters depend on time\n        inputs[intermediate_or_leaf_var] = engine_callable(inputs)\n    self._tracked_vars_identified = True\n    return inputs\n</code></pre>"},{"location":"embed/#pyqtorch.embed.Embedding.reembed_tparam","title":"<code>reembed_tparam(embedded_params, tparam_value)</code>","text":"<p>Receive already embedded params containing intermediate and leaf parameters and recalculate the those which are dependent on <code>tparam_name</code> using the new value <code>tparam_value</code>.</p> Source code in <code>pyqtorch/embed.py</code> <pre><code>def reembed_tparam(\n    self,\n    embedded_params: dict[str, ArrayLike],\n    tparam_value: ArrayLike,\n) -&gt; dict[str, ArrayLike]:\n    \"\"\"Receive already embedded params containing intermediate and leaf parameters\n    and recalculate the those which are dependent on `tparam_name` using the new value\n    `tparam_value`.\n    \"\"\"\n    if self.tparam_name is None:\n        raise ValueError(\n            \"`reembed_param` requires a `tparam_name` to be passed\\\n                          when initializing the `Embedding` class\"\n        )\n    embedded_params[self.tparam_name] = tparam_value\n    for time_dependent_param in self.tracked_vars:\n        embedded_params[time_dependent_param] = self.var_to_call[\n            time_dependent_param\n        ](embedded_params)\n    return embedded_params\n</code></pre>"},{"location":"fitting_a_function/","title":"Fitting a nonlinear function","text":"<p>Let's have a look at how the <code>QuantumCircuit</code> can be used to fit a simple nonlienar function.</p> <pre><code>from __future__ import annotations\n\nfrom operator import add\nfrom functools import reduce\nimport torch\nimport pyqtorch as pyq\nfrom pyqtorch.circuit import hea\nfrom pyqtorch.utils import DiffMode\nfrom pyqtorch.parametric import Parametric\nimport matplotlib.pyplot as plt\n\nfrom torch.nn.functional import mse_loss\n\n# We can train on GPU if available\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# We can also choose the precision we want to train on\nCOMPLEX_DTYPE = torch.complex64\nREAL_DTYPE = torch.float32\nN_QUBITS = 4\nDEPTH = 2\nLR = .2\nDIFF_MODE = DiffMode.ADJOINT\nN_EPOCHS = 75\n\n# Target function and some training data\nfn = lambda x, degree: .05 * reduce(add, (torch.cos(i*x) + torch.sin(i*x) for i in range(degree)), 0)\nx = torch.linspace(0, 10, 100)\ny = fn(x, 5)\n# Lets define a feature map to encode our 'x' values\nfeature_map = [pyq.RX(i, f'x') for i in range(N_QUBITS)]\n# To fit the function, we define a hardware-efficient ansatz with tunable parameters\nansatz, params = hea(N_QUBITS, DEPTH, 'theta')\n# Lets move all necessary components to the DEVICE\ncirc = pyq.QuantumCircuit(N_QUBITS, feature_map + ansatz).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nobservable = pyq.DiagonalObservable(N_QUBITS, pyq.Z(0)).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nparams = params.to(device=DEVICE, dtype=REAL_DTYPE)\nx, y = x.to(device=DEVICE, dtype=REAL_DTYPE), y.to(device=DEVICE, dtype=REAL_DTYPE)\nstate = circ.init_state()\n\ndef exp_fn(params: dict[str, torch.Tensor], inputs: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n    return pyq.expectation(circ, state, {**params,**inputs}, observable, DIFF_MODE)\n\nwith torch.no_grad():\n    y_init = exp_fn(params, {'x': x})\n\n# We need to set 'foreach' False since Adam doesnt support float64 on CUDA devices\noptimizer = torch.optim.Adam(params.values(), lr=LR, foreach=False)\n\nfor _ in range(N_EPOCHS):\n    optimizer.zero_grad()\n    y_pred = exp_fn(params, {'x': x})\n    loss = mse_loss(y, y_pred)\n    loss.backward()\n    optimizer.step()\n\nwith torch.no_grad():\n    y_final = exp_fn(params, {'x': x})\n\nplt.figure()\nplt.plot(x.numpy(), y.numpy(), label=\"truth\")\nplt.plot(x.numpy(), y_init.numpy(), label=\"initial\")\nplt.plot(x.numpy(), y_final.numpy(), \"--\", label=\"final\", linewidth=3)\nplt.legend()\n</code></pre> 2024-07-16T08:20:56.608497 image/svg+xml Matplotlib v3.9.1, https://matplotlib.org/"},{"location":"noise/","title":"Digital noisy simulation","text":"<p>In the description of closed quantum systems, a pure state vector is used to represent the complete quantum state. Thus, pure quantum states are represented by state vectors \\(\\ket{\\psi}\\).</p> <p>However, this description is not sufficient to study open quantum systems. When the system interacts with its environment, quantum systems can be in a mixed state, where quantum information is no longer entirely contained in a single state vector but is distributed probabilistically.</p> <p>To address these more general cases, we consider a probabilistic combination \\(p_i\\) of possible pure states \\(\\ket{\\psi_i}\\). Thus, the system is described by a density matrix \\(\\rho\\) defined as follows:</p> \\[ \\rho = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i| \\] <p>The transformations of the density operator of an open quantum system interacting with its environment (noise) are represented by the super-operator \\(S: \\rho \\rightarrow S(\\rho)\\), often referred to as a quantum channel. Quantum channels, due to the conservation of the probability distribution, must be CPTP (Completely Positive and Trace Preserving). Any CPTP super-operator can be written in the following form:</p> \\[ S(\\rho) = \\sum_i K_i \\rho K^{\\dagger}_i \\] <p>Where \\(K_i\\) are the Kraus operators, and satisfy the property \\(\\sum_i K_i K^{\\dagger}_i = \\mathbb{I}\\). As noise is the result of system interactions with its environment, it is therefore possible to simulate noisy quantum circuit with noise type gates.</p> <p>Thus, <code>pyqtorch</code> implements a large selection of single qubit noise gates such as:</p> <ul> <li>The bit flip channel defined as:     $$         \\textbf{BitFlip}(\\rho) =(1-p) \\rho + p X \\rho X^{\\dagger}     $$</li> <li>The phase flip channel defined as:     $$         \\textbf{PhaseFlip}(\\rho) = (1-p) \\rho + p Z \\rho Z^{\\dagger}     $$</li> <li>The depolarizing channel defined as:     $$         \\textbf{Depolarizing}(\\rho) = (1-p) \\rho + \\frac{p}{3} (X \\rho X^{\\dagger}             + Y \\rho Y^{\\dagger}             + Z \\rho Z^{\\dagger})     $$</li> <li>The pauli channel defined as:     $$         \\textbf{PauliChannel}(\\rho) = (1-p_x-p_y-p_z) \\rho             + p_x X \\rho X^{\\dagger}             + p_y Y \\rho Y^{\\dagger}             + p_z Z \\rho Z^{\\dagger}     $$</li> <li>The amplitude damping channel defined as:     $$         \\textbf{AmplitudeDamping}(\\rho) =  K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger}     $$     with:     \\(\\begin{equation*}     K_{0} \\ =\\begin{pmatrix}     1 &amp; 0\\\\     0 &amp; \\sqrt{1-\\ \\gamma }     \\end{pmatrix} ,\\ K_{1} \\ =\\begin{pmatrix}     0 &amp; \\sqrt{\\ \\gamma }\\\\     0 &amp; 0     \\end{pmatrix}     \\end{equation*}\\)</li> <li>The phase damping channel defined as:     $$         \\textbf{PhaseDamping}(\\rho) = K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger}     $$     with:     \\(\\begin{equation*}     K_{0} \\ =\\begin{pmatrix}     1 &amp; 0\\\\     0 &amp; \\sqrt{1-\\ \\gamma }     \\end{pmatrix}, \\ K_{1} \\ =\\begin{pmatrix}     0 &amp; 0\\\\     0 &amp; \\sqrt{\\ \\gamma }     \\end{pmatrix}     \\end{equation*}\\)</li> <li>The generalize amplitude damping channel is defined as:     $$         \\textbf{GeneralizedAmplitudeDamping}(\\rho) = K_0 \\rho K_0^{\\dagger} + K_1 \\rho K_1^{\\dagger}             + K_2 \\rho K_2^{\\dagger} + K_3 \\rho K_3^{\\dagger}     $$     with: \\(\\begin{cases} K_{0} \\ =\\sqrt{p} \\ \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; \\sqrt{1-\\ \\gamma } \\end{pmatrix} ,\\ K_{1} \\ =\\sqrt{p} \\ \\begin{pmatrix} 0 &amp; 0\\\\ 0 &amp; \\sqrt{\\ \\gamma } \\end{pmatrix} \\\\ K_{2} \\ =\\sqrt{1\\ -p} \\ \\begin{pmatrix} \\sqrt{1-\\ \\gamma } &amp; 0\\\\ 0 &amp; 1 \\end{pmatrix} ,\\ K_{3} \\ =\\sqrt{1-p} \\ \\begin{pmatrix} 0 &amp; 0\\\\ \\sqrt{\\ \\gamma } &amp; 0 \\end{pmatrix} \\end{cases}\\)</li> </ul> <p>Noise gates are <code>Primitive</code> types, but they also request a <code>probability</code> argument to represent the noise affecting the system. And either a vector or a density matrix can be used as an input, but the output will always be a density matrix.</p> <pre><code>import torch\nfrom pyqtorch.noise import AmplitudeDamping, PhaseFlip\nfrom pyqtorch.utils import random_state\n\ninput_state = random_state(n_qubits=2)\nnoise_prob = 0.3\nAmpD = AmplitudeDamping(0,noise_prob)\noutput_state = AmpD(input_state) #It's a density matrix\npf = PhaseFlip(1,0.7)\noutput_state = pf(output_state)\n</code></pre> <p>Noisy circuit initialization is the same as noiseless ones and the output will always be a density matrix. Let\u2019s show its usage through the simulation of a realistic \\(X\\) gate.</p> <p>We know that an \\(X\\) gate flips the state of the qubit, for instance \\(X|0\\rangle = |1\\rangle\\). In practice, it's common for the target qubit to stay in its original state after applying \\(X\\) due to the interactions between it and its environment. The possibility of failure can be represented by a <code>BitFlip</code> gate, which flips the state again after the application of the \\(X\\) gate, returning it to its original state with a probability <code>1 - gate_fidelity</code>.</p> <pre><code>import matplotlib.pyplot as plt\nimport torch\n\nfrom pyqtorch.circuit import QuantumCircuit\nfrom pyqtorch.noise import BitFlip\nfrom pyqtorch.primitive import X\nfrom pyqtorch.utils import product_state\n\n\ninput_state = product_state('00')\nx = X(0)\ngate_fidelity = 0.9\nbf = BitFlip(0,1.-gate_fidelity)\ncirc = QuantumCircuit(2,[x,bf])\noutput_state = circ(input_state)\noutput_state_diag = output_state.diagonal(dim1=0).real\n\nplt.figure()\ndiag_values = output_state_diag.squeeze().numpy()\nplt.bar(range(len(diag_values)), diag_values, color='blue', alpha=0.7)\ncustom_labels = ['00', '01', '10', '11']\nplt.xticks(range(len(diag_values)), custom_labels)\nplt.title(\"Probability of state occurrence\")\nplt.xlabel('Possible States')\nplt.ylabel('Probability')\n</code></pre> 2024-07-16T08:20:56.680259 image/svg+xml Matplotlib v3.9.1, https://matplotlib.org/"},{"location":"pde/","title":"Solving a partial differential equation using DQC","text":"<p><code>pyqtorch</code> can also be used to implement DQC to solve a partial differential equation.</p> <pre><code>from __future__ import annotations\n\nfrom functools import reduce\nfrom itertools import product\nfrom operator import add\nfrom typing import Callable\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import Tensor, exp, linspace, ones_like, optim, rand, sin, tensor\nfrom torch.autograd import grad\nfrom pyqtorch.circuit import hea\nfrom pyqtorch import CNOT, RX, RY, QuantumCircuit, Z, expectation, DiagonalObservable, Sequence, Merge, Add\nfrom pyqtorch.parametric import Parametric\nfrom pyqtorch.utils import DiffMode\n\nDIFF_MODE = DiffMode.AD\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n# We can also choose the precision we want to train on\nCOMPLEX_DTYPE = torch.complex64\nREAL_DTYPE = torch.float32\nLR = .15\nN_QUBITS = 4\nDEPTH = 3\nVARIABLES = (\"x\", \"y\")\nN_VARIABLES = len(VARIABLES)\nX_POS, Y_POS = [i for i in range(N_VARIABLES)]\nBATCH_SIZE = 250\nN_EPOCHS = 750\n\n\nclass DomainSampling(torch.nn.Module):\n    def __init__(\n        self, exp_fn: Callable[[Tensor], Tensor], n_inputs: int, batch_size: int, device: torch.device, dtype: torch.dtype\n    ) -&gt; None:\n        super().__init__()\n        self.exp_fn = exp_fn\n        self.n_inputs = n_inputs\n        self.batch_size = batch_size\n        self.device = device\n        self.dtype = dtype\n\n    def sample(self, requires_grad: bool = False) -&gt; Tensor:\n        return rand((self.batch_size, self.n_inputs), requires_grad=requires_grad, device=self.device, dtype=self.dtype)\n\n    def left_boundary(self) -&gt; Tensor:  # u(0,y)=0\n        sample = self.sample()\n        sample[:, X_POS] = 0.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def right_boundary(self) -&gt; Tensor:  # u(L,y)=0\n        sample = self.sample()\n        sample[:, X_POS] = 1.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def top_boundary(self) -&gt; Tensor:  # u(x,H)=0\n        sample = self.sample()\n        sample[:, Y_POS] = 1.0\n        return self.exp_fn(sample).pow(2).mean()\n\n    def bottom_boundary(self) -&gt; Tensor:  # u(x,0)=f(x)\n        sample = self.sample()\n        sample[:, Y_POS] = 0.0\n        return (self.exp_fn(sample) - sin(np.pi * sample[:, 0])).pow(2).mean()\n\n    def interior(self) -&gt; Tensor:  # uxx+uyy=0\n        sample = self.sample(requires_grad=True)\n        f = self.exp_fn(sample)\n        dfdxy = grad(\n            f,\n            sample,\n            ones_like(f),\n            create_graph=True,\n        )[0]\n        dfdxxdyy = grad(\n            dfdxy,\n            sample,\n            ones_like(dfdxy),\n        )[0]\n\n        return (dfdxxdyy[:, X_POS] + dfdxxdyy[:, Y_POS]).pow(2).mean()\n\n\nfeature_map = [RX(i, VARIABLES[X_POS]) for i in range(N_QUBITS // 2)] + [\n    RX(i, VARIABLES[Y_POS]) for i in range(N_QUBITS // 2, N_QUBITS)\n]\nansatz, params = hea(N_QUBITS, DEPTH, \"theta\")\ncirc = QuantumCircuit(N_QUBITS, feature_map + ansatz).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nsumZ_obs = DiagonalObservable(N_QUBITS, Add(Sequence([Z(i) for i in range(N_QUBITS)]))).to(device=DEVICE, dtype=COMPLEX_DTYPE)\nparams = params.to(device=DEVICE, dtype=REAL_DTYPE)\nstate = circ.init_state()\n\n\ndef exp_fn(inputs: Tensor) -&gt; Tensor:\n    return expectation(\n        circ,\n        state,\n        {**params, **{VARIABLES[X_POS]: inputs[:, X_POS], VARIABLES[Y_POS]: inputs[:, Y_POS]}},\n        sumZ_obs,\n        DIFF_MODE,\n    )\n\n\nsingle_domain_torch = linspace(0, 1, steps=BATCH_SIZE)\ndomain_torch = tensor(list(product(single_domain_torch, single_domain_torch)))\n\nopt = optim.Adam(params.values(), lr=LR)\nsol = DomainSampling(exp_fn, len(VARIABLES), BATCH_SIZE, DEVICE, REAL_DTYPE)\n\nfor _ in range(N_EPOCHS):\n    opt.zero_grad()\n    loss = (\n        sol.left_boundary()\n        + sol.right_boundary()\n        + sol.top_boundary()\n        + sol.bottom_boundary()\n        + sol.interior()\n    )\n    loss.backward()\n    opt.step()\n\ndqc_sol = exp_fn(domain_torch.to(DEVICE)).reshape(BATCH_SIZE, BATCH_SIZE).detach().cpu().numpy()\nanalytic_sol = (\n    (exp(-np.pi * domain_torch[:, X_POS]) * sin(np.pi * domain_torch[:, Y_POS]))\n    .reshape(BATCH_SIZE, BATCH_SIZE)\n    .T\n).numpy()\n\n\nfig, ax = plt.subplots(1, 2, figsize=(7, 7))\nax[0].imshow(analytic_sol, cmap=\"turbo\")\nax[0].set_xlabel(\"x\")\nax[0].set_ylabel(\"y\")\nax[0].set_title(\"Analytical solution u(x,y)\")\nax[1].imshow(dqc_sol, cmap=\"turbo\")\nax[1].set_xlabel(\"x\")\nax[1].set_ylabel(\"y\")\nax[1].set_title(\"DQC solution\")\n</code></pre> 2024-07-16T08:24:16.074301 image/svg+xml Matplotlib v3.9.1, https://matplotlib.org/"},{"location":"time_dependent/","title":"Time-dependent simulation","text":""},{"location":"time_dependent/#time-dependent-schrodinger-and-lindblad-master-equation-solving","title":"Time-dependent Schr\u00f6dinger and Lindblad master equation solving","text":"<p>For simulating systems described by time-dependent Hamiltonians <code>pyqtorch</code> has a  module implementing Schr\u00f6dinger and Lindblad equation solvers.</p> <pre><code>import torch\nfrom torch import Tensor\nfrom pyqtorch.utils import product_state, operator_kron\nfrom pyqtorch.matrices import XMAT, YMAT, IMAT\nfrom pyqtorch.time_dependent.mesolve import mesolve\nfrom pyqtorch.time_dependent.sesolve import sesolve\nfrom pyqtorch.utils import SolverType\n\nn_qubits = 2\nduration = 1.0  # simulation duration\nn_steps = 1000  # number of solver time steps\n\n# prepare initial state\ninput_state = product_state(\"0\"*n_qubits).reshape((-1, 1))\n\n# prepare time-dependent Hamiltonian function\ndef ham_t(t: float) -&gt; Tensor:\n    t = torch.as_tensor(t)\n    return 10.0 * (\n        2.0 * torch.sin(t) * torch.kron(XMAT, torch.eye(2))\n        + 3.0 * t**2 * torch.kron(torch.eye(2), YMAT)\n    )\n\n# solve Schrodinger equation for the system\nt_points = torch.linspace(0, duration, n_steps)\nfinal_state_se = sesolve(ham_t, input_state, t_points, SolverType.DP5_SE).states[-1]\n\n# define jump operator L and solve Lindblad master equation\nL = IMAT.clone()\nfor i in range(n_qubits-1):\n    L = torch.kron(L, XMAT)\nfinal_state_me = mesolve(ham_t, input_state, [L], t_points, SolverType.DP5_ME).states[-1]\n</code></pre>"}]}